Jianfei Shi
David Shilane
April 23, 2023
Kaggle Report: Sound of Music

As I explored the variables of the dataset, I have found so many factors that contribute to the rating of a song. There are a couple of dependent variables that drew my attention the most, such as track_duration, track_explicit, key, and tempo. Despite the fact that more variables included in the model indicate more “accuracy”, I would rather pick up the ones that could be fully applied as indicators for song rating. 
To begin with, I cleaned the dataset by applying sum(is.na(songs)) from dplyr library. I also used a series of cleaning prompt respectively for categorical variables and factor variables, such as as.numeric(track_duration) and as.factor(mode). To discover the average of the dependent variables, I chose linear regression for most of models to test the correlation between rating and dependent factors.
When I compared the best model and the worst model that I built, I found that the new model has many highlights and revisions which indeed worth the credits. In addition to cleaning the data, the model that received the highest score split the data by setting seed to 1031, and applied createDataPartition function to group data into 70:30 with train and test. Along with building the ultimate model, I used boosting model from library(gbm) to obtain accurate outcomes, since it is capable of deriving predictions from a number of trees. What makes the model differentiated from the others is that boosting model can grow trees sequentially based on previously grown ones. In other words, dependent variables can be estimated and tuned to achieve precise outcomes. 
Besides the success received from models, failed steps should require much attention and caution. When I tried to expand the scope of included variables, I discovered that categorical variables, like performer, song, or genre, could not manage to go through prediction for model. It would cause the data frame unmatched with scoring data set. Moreover, when using ranger function to create regression model, it turned out that the column of “prediction” was unexpected and the “rating” could not be found. Even if I checked commands of the ranger model step by step, it still raised concerns on how and why the errors occurred. 
Speaking of the development on the model, I would suggest improvement on the current one that applies to tangible or intangible object with different dimensions of data. For example, it would be capable of analyzing a bottle of water with its branding, quality, aesthetics, and more. The application of the model in marketing field would benefit organization to better analyze and promote products furthermore. In addition, we might also utilize the model to forecast which kind of product or service customers like in the next quarter or year. In this competition case, we may feed the model, for instance, with different dataset of songs but with same element of variables, such as loudness and key. By comparing the results from sample to sample, it helps the chief analytics officer of a musical production company to make strategic decisions on what areas of business should the company focus on. If the jazz style of music comes with a better outcome with lower rmse, he or she could offer valuable opinions on board and suggest business likelihood on jazz music production in the near future. 
To sum up, as I developed the model utilizing course materials, it possesses much more potentials containing many aspects of variables and analysis ability. With the process of splitting and cleaning data, the model can capitalize on analyzing the outcome from boosting model, forest model, and more potential variations along. Although it did not perform as optimal, I believe that with further adjustment it will be capable and applicable in real-life scenarios such as marketing campaign and research analysis.